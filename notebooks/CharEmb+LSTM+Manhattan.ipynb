{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuoraQuesDupSetup.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBTEssVNS3bh",
        "colab_type": "code",
        "outputId": "5aba4af0-e1f0-428b-d85b-78d06754b7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install autocorrect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/b6/6c74ff19249dc6d7285541cd59f5a3edbbd0f7209362a63e314fc09b2636/autocorrect-0.3.0.tar.gz (3.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.6MB 11.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bf/b8/ae/704d5643f1d0637c5b87d9feccf2ee923c492b703bb0bfbb19\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFd2r_6VTogj",
        "colab_type": "code",
        "outputId": "b360d072-4c3c-43b9-b472-0e306deecba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnAQQUfMXdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3_ni0JnTsjt",
        "colab_type": "code",
        "outputId": "1397f4c1-438a-4c7a-e1ed-73f5490ef255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcubMLeoT9qt",
        "colab_type": "code",
        "outputId": "dc25a10f-734d-46aa-c743-48fb66b2a87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1r7SG7KUNbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xYZ8YxzVQaj",
        "colab_type": "code",
        "outputId": "d753745b-90ea-46d2-baec-9ad7d7be8cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd quora-question-duplicates/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/quora-question-duplicates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axv6mC2mVTI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/questions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RrqxqtyWZ0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainDf,testDf = train_test_split(df, test_size=0.2,stratify=df['is_duplicate'].values)\n",
        "trainDf.to_csv('data/train.csv',index=False)\n",
        "testDf.to_csv('data/test.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8q1CxtRXWht",
        "colab_type": "code",
        "outputId": "184e8309-a7fe-46d0-adb7-7f39bc4b3aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mdemo\u001b[0m/  LICENSE  \u001b[01;34mmodels\u001b[0m/  README.md  requirement.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsJCh7R3aYPu",
        "colab_type": "code",
        "outputId": "805957d6-3474-4ef3-9f87-b73c53f16e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/quora-question-duplicates/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DONGg6Epab66",
        "colab_type": "code",
        "outputId": "9f750caf-e1df-442b-d7c5-c9302171c75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_processing.py    Model.03-0.7335.hdf5  Model.07-0.7930.hdf5\n",
            "embeddings.py         Model.04-0.7507.hdf5  tf_idf_scores.py\n",
            "Model.01-0.6896.hdf5  Model.05-0.7753.hdf5  topic_modeling.py\n",
            "Model.02-0.7158.hdf5  Model.06-0.7849.hdf5  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oHIW5_7ac0K",
        "colab_type": "code",
        "outputId": "c6d827a3-e378-498c-b46c-bc0523a06174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1508
        }
      },
      "source": [
        "!python data_processing.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "completed 10000\n",
            "completed 20000\n",
            "completed 30000\n",
            "completed 40000\n",
            "completed 50000\n",
            "completed 60000\n",
            "completed 70000\n",
            "completed 80000\n",
            "Finished Question1\n",
            "completed 90000\n",
            "completed 100000\n",
            "completed 110000\n",
            "completed 120000\n",
            "completed 130000\n",
            "completed 140000\n",
            "completed 150000\n",
            "completed 160000\n",
            "Finished Question2\n",
            "Finished processing file ../data/test.csv\n",
            "completed 170000\n",
            "completed 180000\n",
            "completed 190000\n",
            "completed 200000\n",
            "completed 210000\n",
            "completed 220000\n",
            "completed 230000\n",
            "completed 240000\n",
            "completed 250000\n",
            "completed 260000\n",
            "completed 270000\n",
            "completed 280000\n",
            "completed 290000\n",
            "completed 300000\n",
            "completed 310000\n",
            "completed 320000\n",
            "completed 330000\n",
            "completed 340000\n",
            "completed 350000\n",
            "completed 360000\n",
            "completed 370000\n",
            "completed 380000\n",
            "completed 390000\n",
            "completed 400000\n",
            "completed 410000\n",
            "completed 420000\n",
            "completed 430000\n",
            "completed 440000\n",
            "completed 450000\n",
            "completed 460000\n",
            "completed 470000\n",
            "completed 480000\n",
            "Finished Question1\n",
            "completed 490000\n",
            "completed 500000\n",
            "completed 510000\n",
            "completed 520000\n",
            "completed 530000\n",
            "completed 540000\n",
            "completed 550000\n",
            "completed 560000\n",
            "completed 570000\n",
            "completed 580000\n",
            "completed 590000\n",
            "completed 600000\n",
            "completed 610000\n",
            "completed 620000\n",
            "completed 630000\n",
            "completed 640000\n",
            "completed 650000\n",
            "completed 660000\n",
            "completed 670000\n",
            "completed 680000\n",
            "completed 690000\n",
            "completed 700000\n",
            "completed 710000\n",
            "completed 720000\n",
            "completed 730000\n",
            "completed 740000\n",
            "completed 750000\n",
            "completed 760000\n",
            "completed 770000\n",
            "completed 780000\n",
            "completed 790000\n",
            "completed 800000\n",
            "Finished Question2\n",
            "Finished processing file ../data/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwAw4qYPafLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "def get_processed_df(data_dir='../data',file_suffix='processed.csv'):\n",
        "    test_fp = os.path.join(data_dir,'test_'+file_suffix)\n",
        "    train_fp = os.path.join(data_dir,'train_'+file_suffix)\n",
        "    train_df = pd.read_csv(train_fp)\n",
        "    # Drop NA values\n",
        "    train_df = train_df.dropna()\n",
        "    test_df = pd.read_csv(test_fp)\n",
        "    test_df = test_df.dropna()\n",
        "    return train_df,test_df\n",
        "  \n",
        "train_df,test_df = get_processed_df()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkoClYxFdGuf",
        "colab_type": "code",
        "outputId": "222f2cf4-1b09-4af9-fa0a-ceb0e9c12d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(\n",
        "    char_level=True,\n",
        "    filters=None,\n",
        "    lower=False,\n",
        "    num_words=7000\n",
        ")\n",
        "\n",
        "uniq_questions = pd.concat((train_df['question1'],train_df['question2'])).unique()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icvT8STUqjJW",
        "colab_type": "code",
        "outputId": "b7049474-8978-42dd-cf49-9f4960ff6f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.fit_on_texts(uniq_questions)\n",
        "word_index = tokenizer.word_index #unique words in corpus (training and test sets)\n",
        "\n",
        "print(\"Chars in index: %d\" % len(word_index))\n",
        "#sequences = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chars in index: 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdHN2TxTq4rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_char_seq_train = tokenizer.texts_to_sequences(train_df['question1'].values)\n",
        "q2_char_seq_train = tokenizer.texts_to_sequences(train_df['question2'].values)\n",
        "q1_char_seq_test = tokenizer.texts_to_sequences(test_df['question1'].values)\n",
        "q2_char_seq_test = tokenizer.texts_to_sequences(test_df['question2'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWIT4lU2wIAn",
        "colab_type": "code",
        "outputId": "4806c1d4-dfae-4655-a0a3-fe585a68bb22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_len=0\n",
        "for seq in q1_char_seq_test:\n",
        "  if len(seq) > max_len:\n",
        "    max_len = len(seq)\n",
        "print(max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOyyNOYPzFYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MAX_LEN = 1150\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "q1_data = pad_sequences(q1_char_seq_train, maxlen=MAX_LEN)\n",
        "q2_data = pad_sequences(q2_char_seq_train, maxlen=MAX_LEN)\n",
        "test1_data=pad_sequences(q1_char_seq_test, maxlen=MAX_LEN)\n",
        "test2_data=pad_sequences(q2_char_seq_test, maxlen=MAX_LEN)\n",
        "\n",
        "labels = train_df['is_duplicate'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQmrGnmo1CNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,GlobalAveragePooling1D,Lambda,Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCla6zqB1QUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sum(K.square(x - y), axis=1, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10oq7cyV1WZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkwJ72KU1Ywl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "nb_words=40\n",
        "max_sentence_len=MAX_LEN\n",
        "embedding_layer = Embedding(nb_words,300,\n",
        "        input_length=max_sentence_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0WfHqDZ1uU4",
        "colab_type": "code",
        "outputId": "d6d0098d-d46f-4b94-f5f9-1eacc41cda68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "\n",
        "lstm_layer =LSTM(128)\n",
        "\n",
        "sequence_1_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "sequence_2_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "y1 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "distance=Lambda(vec_distance, output_shape=vec_output_shape)([x1, y1])\n",
        "dense1=Dense(16, activation='sigmoid')(distance)\n",
        "dense1 = Dropout(0.3)(dense1)\n",
        "\n",
        "bn2 = BatchNormalization()(dense1)\n",
        "prediction=Dense(1, activation='sigmoid')(bn2)\n",
        "\n",
        "model = Model(input=[sequence_1_input, sequence_2_input], output=prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co00Oyx-2Mtc",
        "colab_type": "code",
        "outputId": "7f8d2eb1-01c9-4e58-8ec0-ebc2b2d50b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1150)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1150)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1150, 300)    12000       input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
            "                                                                 embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 16)           32          lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16)           64          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            17          batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 231,761\n",
            "Trainable params: 231,729\n",
            "Non-trainable params: 32\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3YWFFqW2Uxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['acc'])\n",
        "\n",
        "filepath='Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='auto',period=1)\n",
        "\n",
        "#model.fit([q1_data, q2_data], labels, validation_data=([test1_data, test2_data], test_df['is_duplicate'].values), verbose=1, \n",
        " #         epochs=10, batch_size=256, shuffle=True,callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28xRWKsz-9j3",
        "colab_type": "code",
        "outputId": "fc6b929d-1043-4834-feb8-748e67c7fd60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "# Load saved weights\n",
        "model.load_weights('Model.05-0.8236.hdf5')\n",
        "\n",
        "model.fit([q1_data, q2_data], labels, validation_data=([test1_data, test2_data], test_df['is_duplicate'].values), verbose=1, \n",
        "          epochs=10, batch_size=256, shuffle=True,callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 323465 samples, validate on 80869 samples\n",
            "Epoch 1/10\n",
            "323465/323465 [==============================] - 5504s 17ms/step - loss: 0.3194 - acc: 0.8615 - val_loss: 0.4367 - val_acc: 0.8047\n",
            "\n",
            "Epoch 00001: saving model to Model.01-0.8047.hdf5\n",
            "Epoch 2/10\n",
            "323465/323465 [==============================] - 5452s 17ms/step - loss: 0.3336 - acc: 0.8555 - val_loss: 0.4202 - val_acc: 0.8197\n",
            "\n",
            "Epoch 00002: saving model to Model.02-0.8197.hdf5\n",
            "Epoch 3/10\n",
            "323465/323465 [==============================] - 5459s 17ms/step - loss: 0.2995 - acc: 0.8720 - val_loss: 0.4152 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00003: saving model to Model.03-0.8179.hdf5\n",
            "Epoch 4/10\n",
            "323465/323465 [==============================] - 5443s 17ms/step - loss: 0.2864 - acc: 0.8778 - val_loss: 0.4247 - val_acc: 0.8239\n",
            "\n",
            "Epoch 00004: saving model to Model.04-0.8239.hdf5\n",
            "Epoch 5/10\n",
            "323465/323465 [==============================] - 5483s 17ms/step - loss: 0.2807 - acc: 0.8808 - val_loss: 0.4226 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00005: saving model to Model.05-0.8240.hdf5\n",
            "Epoch 6/10\n",
            "323465/323465 [==============================] - 5484s 17ms/step - loss: 0.2843 - acc: 0.8788 - val_loss: 0.4315 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00006: saving model to Model.06-0.8228.hdf5\n",
            "Epoch 7/10\n",
            " 92672/323465 [=======>......................] - ETA: 59:43 - loss: 0.2864 - acc: 0.8780"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTAoYJd6uCWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}