{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgb_topic_model",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-zmZVRTM_db",
        "colab_type": "code",
        "outputId": "d68afd88-1478-407b-d6ec-3a46c0963cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!git clone https://github.com/akg92/quora-question-duplicates.git\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "Cloning into 'quora-question-duplicates'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 81 (delta 24), reused 70 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNW2PmVXPyo3",
        "colab_type": "code",
        "outputId": "f7e0d705-a6cf-4be8-e6f9-9ee866b64f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!ls data\n",
        "!pip install autocorrect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'data': No such file or directory\n",
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/b6/6c74ff19249dc6d7285541cd59f5a3edbbd0f7209362a63e314fc09b2636/autocorrect-0.3.0.tar.gz (3.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.6MB 8.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bf/b8/ae/704d5643f1d0637c5b87d9feccf2ee923c492b703bb0bfbb19\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyfPfRDBNOhM",
        "colab_type": "code",
        "outputId": "40b6150c-5e50-4cbb-cc02-1169f2612ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "data_file = '/gdrive/My Drive/quora/train.csv'\n",
        "lda_model = '/gdrive/My Drive/quora/lda/lda_model.h5'\n",
        "os.chdir('./quora-question-duplicates')\n",
        "!cd quora-question-duplicates"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: quora-question-duplicates: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM8nZAzBNbY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "df = pd.read_csv(data_file)\n",
        "\n",
        "trainDf,testDf = train_test_split(df, test_size=0.2,stratify=df['is_duplicate'].values)\n",
        "trainDf.to_csv('data/train.csv',index=False)\n",
        "testDf.to_csv('data/test.csv',index=False)\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "def get_processed_df(data_dir='./data',file_suffix='processed.csv'):\n",
        "    test_fp = os.path.join(data_dir,'test_'+file_suffix)\n",
        "    train_fp = os.path.join(data_dir,'train_'+file_suffix)\n",
        "    train_df = pd.read_csv(train_fp)\n",
        "    # Drop NA values\n",
        "    train_df = train_df.dropna()\n",
        "    test_df = pd.read_csv(test_fp)\n",
        "    test_df = test_df.dropna()\n",
        "    return train_df,test_df\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkmyOxD0RWmW",
        "colab_type": "code",
        "outputId": "822b89e5-0a7c-4932-f3ca-07ffc078d463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('./models')\n",
        "from data_processing import clean_and_save\n",
        "data_dir = './data'\n",
        "test_file = os.path.join(data_dir,'test.csv')\n",
        "train_file = os.path.join(data_dir,'train.csv')\n",
        "test_processed_file = os.path.join(data_dir,'test_processed.csv')\n",
        "train_processed_file  = os.path.join(data_dir,'train_processed.csv')\n",
        "    #print(test_file)import sys\n",
        "sys.path.append('./models')\n",
        "    ## train and save the files\n",
        "    ## to avoid spell coreect comment the below line\n",
        "ENABLE_SPELL_CORRECT = False\n",
        "\"\"\" for single process uncomment below\"\"\"\n",
        "clean_and_save(test_file,test_processed_file)\n",
        "clean_and_save(train_file,train_processed_file)\n",
        "#!python models/data_processing.py\n",
        "train_df,test_df = get_processed_df()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "completed 10000\n",
            "completed 20000\n",
            "completed 30000\n",
            "completed 40000\n",
            "completed 50000\n",
            "completed 60000\n",
            "completed 70000\n",
            "completed 80000\n",
            "Finished Question1\n",
            "completed 90000\n",
            "completed 100000\n",
            "completed 110000\n",
            "completed 120000\n",
            "completed 130000\n",
            "completed 140000\n",
            "completed 150000\n",
            "completed 160000\n",
            "Finished Question2\n",
            "Finished processing file ./data/test.csv\n",
            "completed 170000\n",
            "completed 180000\n",
            "completed 190000\n",
            "completed 200000\n",
            "completed 210000\n",
            "completed 220000\n",
            "completed 230000\n",
            "completed 240000\n",
            "completed 250000\n",
            "completed 260000\n",
            "completed 270000\n",
            "completed 280000\n",
            "completed 290000\n",
            "completed 300000\n",
            "completed 310000\n",
            "completed 320000\n",
            "completed 330000\n",
            "completed 340000\n",
            "completed 350000\n",
            "completed 360000\n",
            "completed 370000\n",
            "completed 380000\n",
            "completed 390000\n",
            "completed 400000\n",
            "completed 410000\n",
            "completed 420000\n",
            "completed 430000\n",
            "completed 440000\n",
            "completed 450000\n",
            "completed 460000\n",
            "completed 470000\n",
            "completed 480000\n",
            "Finished Question1\n",
            "completed 490000\n",
            "completed 500000\n",
            "completed 510000\n",
            "completed 520000\n",
            "completed 530000\n",
            "completed 540000\n",
            "completed 550000\n",
            "completed 560000\n",
            "completed 570000\n",
            "completed 580000\n",
            "completed 590000\n",
            "completed 600000\n",
            "completed 610000\n",
            "completed 620000\n",
            "completed 630000\n",
            "completed 640000\n",
            "completed 650000\n",
            "completed 660000\n",
            "completed 670000\n",
            "completed 680000\n",
            "completed 690000\n",
            "completed 700000\n",
            "completed 710000\n",
            "completed 720000\n",
            "completed 730000\n",
            "completed 740000\n",
            "completed 750000\n",
            "completed 760000\n",
            "completed 770000\n",
            "completed 780000\n",
            "completed 790000\n",
            "completed 800000\n",
            "Finished Question2\n",
            "Finished processing file ./data/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Haaxu-DdOgEv",
        "colab_type": "code",
        "outputId": "498c083f-d495-4366-82b2-f1544675fb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('./models')\n",
        "from topic_modeling import build_topics_scores\n",
        "train_df,test_df = build_topics_scores(train_df,test_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s6kj4MiUA2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_Y = train_df['is_duplicate']\n",
        "test_Y = test_df['is_duplicate']\n",
        "test_df.drop(['is_duplicate'],axis=1,inplace=True)\n",
        "train_df.drop(['is_duplicate'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI3f30GzSddD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgbmodel import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle\n",
        "\n",
        "params = {\n",
        "        'min_child_weight': [1,3, 5],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }\n",
        "\n",
        "\n",
        "params = {\n",
        "        'min_child_weight': [1],\n",
        "        'gamma': [0.5],\n",
        "        'subsample': [0.6],\n",
        "        'colsample_bytree': [0.6],\n",
        "        'max_depth': [4]\n",
        "        }\n",
        "search = GridSearcCV(XGBClassifier(),params,cv=4)\n",
        "\n",
        "search.fit(train_df,train_Y)\n",
        "\n",
        "model_save_file = '/gdrive/My Drive/quora/lda/xgb.h5'\n",
        "with open(model_save_file,'wb') as f:\n",
        "  pickle.dump(search.best_estimator_,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbMXnksKUjjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}