{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zm2FEueu3skl"
   },
   "source": [
    "# BERT Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1556512697182,
     "user": {
      "displayName": "Sarwesh Krishnan",
      "photoUrl": "",
      "userId": "07289647168793068799"
     },
     "user_tz": 300
    },
    "id": "u6MTimx2mvKo",
    "outputId": "3a857872-b5ae-49ef-bb07-76d2c2b4e8c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ./outputs *****\n",
      "TPU address is grpc://10.76.240.250:8470\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "# Authenticate, so we can access storage bucket and TPU\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# If you want to use TPU, first switch to tpu runtime in colab\n",
    "USE_TPU = True #@param{type:\"boolean\"}\n",
    "\n",
    "# We will use base uncased bert model, you can give try with large models\n",
    "# For large model TPU is necessary\n",
    "BERT_MODEL = 'uncased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "# Bucket for saving checkpoints and outputs\n",
    "BUCKET = 'quorabert123' #@param {type:\"string\"}\n",
    "BERT_PRETRAINED_DIR = 'gs://{}/outputs'.format(BUCKET)\n",
    "\n",
    "OUTPUT_DIR = './outputs'\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
    "\n",
    "if USE_TPU:\n",
    "  # getting info on TPU runtime\n",
    "  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; Change notebook runtype to TPU'\n",
    "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "  print('TPU address is', TPU_ADDRESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nGLW4s-L6ws"
   },
   "source": [
    "## Model Configs and Hyper Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUNH1_-zHJIH"
   },
   "outputs": [],
   "source": [
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "import run_classifier\n",
    "\n",
    "# Model Hyper Parameters\n",
    "TRAIN_BATCH_SIZE = 32 # For GPU, reduce to 16\n",
    "EVAL_BATCH_SIZE = 8\n",
    "PREDICT_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 2.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_SEQ_LENGTH = 200 \n",
    "\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "ITERATIONS_PER_LOOP = 1000\n",
    "NUM_TPU_CORES = 8\n",
    "VOCAB_FILE = os.path.join(OUTPUT_DIR, 'vocab.txt')\n",
    "CONFIG_FILE = os.path.join(OUTPUT_DIR, 'bert_config.json')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'model.ckpt-22740')\n",
    "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RDGdggFQpFB"
   },
   "source": [
    "## Read Questions Pairs\n",
    "\n",
    "We will read data from TSV file and covert to list of InputExample. For `InputExample` and `DataProcessor` class defination refer to [run_classifier](https://github.com/google-research/bert/blob/master/run_classifier.py) file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RvBsrOrKLJN"
   },
   "outputs": [],
   "source": [
    "class QQPProcessor(run_classifier.DataProcessor):\n",
    "  \"\"\"Processor for the Quora Question pair data set.\"\"\"\n",
    "  \n",
    "  def get_predict_examples(self, sentence_pairs):\n",
    "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
    "    examples = []\n",
    "    for (i, qpair) in enumerate(sentence_pairs):\n",
    "      guid = \"predict-%d\" % (i)\n",
    "      # converting questions to utf-8 and creating InputExamples\n",
    "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
    "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
    "      # We will add label  as 0, because None is not supported in converting to features\n",
    "      examples.append(\n",
    "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=0))\n",
    "    return examples\n",
    "  \n",
    "  def _create_examples(self, lines, set_type):\n",
    "    \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "    examples = []\n",
    "    for (i, line) in enumerate(lines):\n",
    "      guid = \"%s-%d\" % (set_type, i)\n",
    "      if set_type=='test':\n",
    "        # removing header and invalid data\n",
    "        if i == 0 or len(line)!=3:\n",
    "          print(guid, line)\n",
    "          continue\n",
    "        text_a = tokenization.convert_to_unicode(line[1])\n",
    "        text_b = tokenization.convert_to_unicode(line[2])\n",
    "        label = 0 # We will use zero for test as convert_example_to_features doesn't support None\n",
    "      else:\n",
    "        # removing header and invalid data\n",
    "        if i == 0 or len(line)!=6:\n",
    "          continue\n",
    "        text_a = tokenization.convert_to_unicode(line[3])\n",
    "        text_b = tokenization.convert_to_unicode(line[4])\n",
    "        label = int(line[5])\n",
    "      examples.append(\n",
    "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "    return examples\n",
    "\n",
    "  def get_labels(self):\n",
    "    \"return class labels\"\n",
    "    return [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRm65m-_ki05"
   },
   "source": [
    "## Convert to Features\n",
    "\n",
    "We will read examples and tokenize using Wordpiece based tokenization. Finally We will convert to `InputFeatures`.\n",
    "\n",
    "BERT follows below tokenization procedure\n",
    "1.   Instantiate an instance of tokenizer = tokenization.FullTokenizer\n",
    "2.   Tokenize the raw text with tokens = tokenizer.tokenize(raw_text).\n",
    "3.   Truncate to the maximum sequence length.\n",
    "4.   Add the [CLS] and [SEP] tokens in the right place.\n",
    "\n",
    "We need to create `segment_ids`, `input_mask` for `InputFeatures`. `segment_ids` will be `0` for question1 tokens and `1` for question2 tokens.\n",
    "\n",
    "We will use following functions from [run_classifier](https://github.com/google-research/bert/blob/master/run_classifier.py) file for converting examples to features :-\n",
    "\n",
    "\n",
    "1.   `convert_single_example` :- Converts a single `InputExample` into a single `InputFeatures`.\n",
    "2.   `file_based_convert_examples_to_features` :- Convert a set of `InputExamples` to a TF_Record file.\n",
    "\n",
    "For more details observe outputs for below cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GMeF2pc7igA"
   },
   "outputs": [],
   "source": [
    "# Instantiate an instance of QQPProcessor and tokenizer\n",
    "processor = QQPProcessor()\n",
    "label_list = processor.get_labels()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1556512723470,
     "user": {
      "displayName": "Sarwesh Krishnan",
      "photoUrl": "",
      "userId": "07289647168793068799"
     },
     "user_tz": 300
    },
    "id": "OdMc4HkJ7ljr",
    "outputId": "4ef36b09-cf73-48e4-d713-7d7ee3c5294e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################  Processing Training Data #####################\n"
     ]
    }
   ],
   "source": [
    "# Converting training examples to features\n",
    "print(\"################  Processing Training Data #####################\")\n",
    "#TRAIN_TF_RECORD = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
    "train_examples = []\n",
    "num_train_examples = len(train_examples)\n",
    "num_train_steps = int( num_train_examples / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uq8zO7O5Dnq"
   },
   "source": [
    "## Creating Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_aUbDJA1N7w"
   },
   "outputs": [],
   "source": [
    "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
    "                 labels, num_labels, use_one_hot_embeddings):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "  # Bert Model instant \n",
    "  model = modeling.BertModel(\n",
    "      config=bert_config,\n",
    "      is_training=is_training,\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      token_type_ids=segment_ids,\n",
    "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "  # Getting output for last layer of BERT\n",
    "  output_layer = model.get_pooled_output()\n",
    "  \n",
    "  # Number of outputs for last layer\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "  \n",
    "  # We will use one layer on top of BERT pretrained for creating classification model\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "    if is_training:\n",
    "      # 0.1 dropout\n",
    "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "    \n",
    "    # Calcaulte prediction probabilites and loss\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "    return (loss, per_example_loss, logits, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxTo8jgbuRoG"
   },
   "source": [
    "## Model Function Builder for Estimator\n",
    "\n",
    "Based on mode, We will create optimizer for training, evaluation metrics for evalution and estimator spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "An2DFEqX2yDJ"
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "  def model_fn(features, labels, mode, params):  \n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    # reading features input\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "    is_real_example = None\n",
    "    if \"is_real_example\" in features:\n",
    "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
    "    else:\n",
    "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
    "    \n",
    "    # checking if training mode\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # create simple classification model\n",
    "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "        num_labels, use_one_hot_embeddings)\n",
    "    \n",
    "    # getting variables for intialization and using pretrained init checkpoint\n",
    "    tvars = tf.trainable_variables()\n",
    "    initialized_variable_names = {}\n",
    "    scaffold_fn = None\n",
    "    if init_checkpoint:\n",
    "      (assignment_map, initialized_variable_names\n",
    "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "      if use_tpu:\n",
    "\n",
    "        def tpu_scaffold():\n",
    "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "          return tf.train.Scaffold()\n",
    "\n",
    "        scaffold_fn = tpu_scaffold\n",
    "      else:\n",
    "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "    output_spec = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # defining optimizar function\n",
    "      train_op = optimization.create_optimizer(\n",
    "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "      \n",
    "      # Training estimator spec\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          train_op=train_op,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "      # accuracy, loss, auc, F1, precision and recall metrics for evaluation\n",
    "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predictions)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predictions)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predictions)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predictions) \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"eval_loss\": loss,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "\n",
    "      eval_metrics = (metric_fn,\n",
    "                      [per_example_loss, label_ids, logits, is_real_example])\n",
    "      # estimator spec for evalaution\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          eval_metrics=eval_metrics,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    else:\n",
    "      # estimator spec for predictions\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          predictions={\"probabilities\": probabilities},\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    return output_spec\n",
    "\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elGbiKDlamy6"
   },
   "source": [
    "## Creating TPUEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPuYpqW97vMf"
   },
   "outputs": [],
   "source": [
    "# Define TPU configs\n",
    "if USE_TPU:\n",
    "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
    "else:\n",
    "  tpu_cluster_resolver = None\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5qq6yfS7yOw"
   },
   "outputs": [],
   "source": [
    "# create model function for estimator using model function builder\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=INIT_CHECKPOINT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=USE_TPU,\n",
    "    use_one_hot_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1556512723777,
     "user": {
      "displayName": "Sarwesh Krishnan",
      "photoUrl": "",
      "userId": "07289647168793068799"
     },
     "user_tz": 300
    },
    "id": "T6D-ZzhlfeGx",
    "outputId": "ef5f9b68-22bc-407e-957f-c04b16198beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f58bb094840>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3mvc4ifs\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3mvc4ifs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"worker\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.76.240.250:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f58bc912400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.76.240.250:8470', '_evaluation_master': 'grpc://10.76.240.250:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f58bc912ba8>}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    }
   ],
   "source": [
    "# Defining TPU Estimator\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    predict_batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOP8xA32CBjE"
   },
   "source": [
    "## Predictions on Model\n",
    "\n",
    "First We will predict on custom examples.\n",
    "\n",
    "For test set, We will get predictions and save in file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhvA3hEL-2Xt"
   },
   "outputs": [],
   "source": [
    "# examples sentences, feel free to change and try\n",
    "sent_pairs = [(\"how can i improve my english?\", \"how can i become fluent in english?\"), (\"How can i recover old gmail account ?\",\"How can i delete my old gmail account ?\"),\n",
    "             (\"How can i recover old gmail account ?\",\"How can i access my old gmail account ?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49691,
     "status": "ok",
     "timestamp": 1556512772545,
     "user": {
      "displayName": "Sarwesh Krishnan",
      "photoUrl": "",
      "userId": "07289647168793068799"
     },
     "user_tz": 300
    },
    "id": "_CXSUjvgMucd",
    "outputId": "c0c70c87-fa63-41be-f08e-43b139c0a39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******  Predictions on Custom Data ********\n",
      "INFO:tensorflow:Writing example 0 of 8\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: predict-0\n",
      "INFO:tensorflow:tokens: [CLS] how can i improve my english ? [SEP] how can i become fluent in english ? [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2129 2064 1045 5335 2026 2394 1029 102 2129 2064 1045 2468 19376 1999 2394 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: predict-1\n",
      "INFO:tensorflow:tokens: [CLS] how can i recover old gma ##il account ? [SEP] how can i del ##ete my old gma ##il account ? [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2129 2064 1045 8980 2214 20917 4014 4070 1029 102 2129 2064 1045 3972 12870 2026 2214 20917 4014 4070 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: predict-2\n",
      "INFO:tensorflow:tokens: [CLS] how can i recover old gma ##il account ? [SEP] how can i access my old gma ##il account ? [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2129 2064 1045 8980 2214 20917 4014 4070 1029 102 2129 2064 1045 3229 2026 2214 20917 4014 4070 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp3mvc4ifs, running initialization to predict.\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.76.240.250:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2417541332905852030)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16226584232494614688)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10101800543957711466)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 879681069521169039)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12327999338387904751)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8156386493253046039)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2729074657383144183)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4528770198283570726)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11829461239578907929)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3016021553428572887)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 8590029412879165317)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 7 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "[{'probabilities': array([0.9979353 , 0.00206474], dtype=float32)}, {'probabilities': array([0.99840206, 0.00159797], dtype=float32)}, {'probabilities': array([7.4931962e-04, 9.9925077e-01], dtype=float32)}, {'probabilities': array([0.9911089, 0.0088911], dtype=float32)}, {'probabilities': array([0.9911089, 0.0088911], dtype=float32)}, {'probabilities': array([0.9911089, 0.0088911], dtype=float32)}, {'probabilities': array([0.9911089, 0.0088911], dtype=float32)}, {'probabilities': array([0.9911089, 0.0088911], dtype=float32)}]\n",
      "****** Example 0 ******\n",
      "Question1 : how can i improve my english?\n",
      "Question2 : how can i become fluent in english?\n",
      "Prediction : 0.0020647391\n",
      "****** Example 1 ******\n",
      "Question1 : How can i recover old gmail account ?\n",
      "Question2 : How can i delete my old gmail account ?\n",
      "Prediction : 0.001597966\n",
      "****** Example 2 ******\n",
      "Question1 : How can i recover old gmail account ?\n",
      "Question2 : How can i access my old gmail account ?\n",
      "Prediction : 0.99925077\n"
     ]
    }
   ],
   "source": [
    "print(\"*******  Predictions on Custom Data ********\")\n",
    "# create `InputExample` for custom examples\n",
    "predict_examples = processor.get_predict_examples(sent_pairs)\n",
    "num_predict_examples = len(predict_examples)\n",
    "\n",
    "# For TPU, We will append `PaddingExample` for maintaining batch size\n",
    "if USE_TPU:\n",
    "  while(len(predict_examples)%EVAL_BATCH_SIZE!=0):\n",
    "    predict_examples.append(run_classifier.PaddingInputExample())\n",
    "\n",
    "# Converting to features \n",
    "predict_features = run_classifier.convert_examples_to_features(predict_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "print('  Num examples = {}'.format(num_predict_examples))\n",
    "print('  Batch size = {}'.format(PREDICT_BATCH_SIZE))\n",
    "\n",
    "# Input function for prediction\n",
    "predict_input_fn = run_classifier.input_fn_builder(predict_features,\n",
    "                                                seq_length=MAX_SEQ_LENGTH,\n",
    "                                                is_training=False,\n",
    "                                                drop_remainder=True)\n",
    "result = list(estimator.predict(input_fn=predict_input_fn))\n",
    "print(result)\n",
    "for ex_i in range(num_predict_examples):\n",
    "  print(\"****** Example {} ******\".format(ex_i))\n",
    "  print(\"Question1 :\", sent_pairs[ex_i][0])\n",
    "  print(\"Question2 :\", sent_pairs[ex_i][1])\n",
    "  print(\"Prediction :\", result[ex_i]['probabilities'][1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy_of_BERT_FineTuning_Quora_Question_Pairs.ipynb",
   "provenance": [
    {
     "file_id": "1Qt4hM1UONTr4_xGzwWRMaX5XQ-ihuKHR",
     "timestamp": 1556512803830
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
